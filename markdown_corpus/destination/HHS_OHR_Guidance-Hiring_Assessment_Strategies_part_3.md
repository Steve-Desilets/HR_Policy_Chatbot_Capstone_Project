
Reliability: Refers to consistency.
Reliability is important when deciding which assessment to use for a given purpose. The test manual or other documentation supporting the use of an assessment should report details of reliability and how it was computed.

Validity: Refers to the relationship between performance on the assessment and performance on the job. Validity is the most important issue to consider when deciding whether to use a particular assessment tool because an assessment that does not provide useful information about how an individual will perform on the job is of no value to the organization.
There are different types of validity evidence. Which type is most appropriate will depend on how the assessment method is used in making an employment decision. For example, if a work sample test is designed to mimic the actual tasks performed on the job, then a content validity approach may be needed to establish the content of the test matches in a convincing way the content of the job, as identified by a job analysis. If a personality test is intended to forecast the job success of applicants for a customer service position, then evidence of predictive validity may be needed to show scores on the personality test are related to subsequent performance on the job.

NOTE: In most assessment scenarios where an assessment tool or process is used to identify potential new hires for few positions (e.g., a dozen or fewer), a predictive

validity study would not be practical. In such cases, it is sufficient to ensure validity through:

Measuring only job-related competencies identified in a job analysis
Relying on types of assessment tools that demonstrate a strong track record of validity
Technology: Occupations that typically receive a large volume of applicants for vacancy announcements may benefit from using technology to narrow down the applicant pool, such as online screening of resumes or online biographical data (biodata) tests. Technology can also overcome distance challenges and enable OpDivs/StaffDivs to reach a larger population of applicants. However, because technology removes the human element from the assessment process, it is best used in situations that do not rely heavily on human intervention, such as collecting applications or conducting applicant screening.
Legal Context of Assessment: OpDivs/StaffDivs should ensure that any assessment procedure used to make an employment decision does not adversely affect any group of people with characteristics protected by federal anti-discrimination laws. Any assessment procedure must be shown to be job-related and valid for its intended purpose.
Face Validity/Applicant Reaction: The goal of assessment procedures is to measure competencies/knowledge, skills and abilities without alienating or causing undue stress to participating candidates. With this in mind, no less than two (2) assessment tools will be used to assess candidates’ qualifications for technical, professional, or nonprofessional positions (including initial applicant review). The duration of each assessment tool should not exceed one (1) hour. This is to ensure the perception of face validity and overall fairness of the assessment process by candidates.
Minimum Qualifications Versus Assessment Tools;
The purpose of minimum qualifications for a position is to determine who should be allowed (i.e., who is qualified) to participate in the hiring assessments used to determine who will be deemed eligible for placement into a position. For the assessment portion of the process, applicants are expected to achieve a pre-determined passing grade, in order to be rated and ranked for further employment consideration.

Screening applicants for minimum qualification requirements is not the same as assessing applicants on the competencies necessary to perform the job. Screening minimum qualifications on an occupational questionnaire is important, but a “deeper dive” is required, in order to address the actual competencies that have been rated as critical for the job; evaluate who is eligible to perform the particular duties and functions of the position (i.e., those who achieve a passing grade on the assessment); and assess applicants’ relative levels of qualification beyond the passing level. Therefore, applicants who satisfy minimum qualification requirements are not automatically entitled to a qualifying score of 70 or more points, out of 100, when a numerical rating procedure is used. Nor are they entitled to placement in a quality category when a category rating process is used.

Here is an example of a diagram reflecting a sample of the process:

Image
example of a diagram reflecting a sample of the process
For additional information on minimum qualifications and assessments in the GS Qualifications Operating Manual and the use of passing scores with additional examples, see Chapter 5 of the Delegated Examining Operations Handbook. - PDF

Applicant Assessment
A multi-hurdle assessment approach is the use of two or more assessments in the assessment process. The use of multiple assessment tools involve the administration of assessments in sequential steps. After each assessment, candidates’ scores that fall below a predetermined threshold are eliminated and should not proceed to the next steps.

If it meets the hiring need of OpDivs/StaffDivs, using a multi-hurdle approach to determine which applicants are qualified for the position and placed on the certificate of eligibles is an option. Applicants must first complete the first “hurdle” of the assessment process, typically an automated, self-report questionnaire or inexpensive online test. The HRS also participates in this first hurdle by reviewing applicant resumes to ensure that minimum qualification requirements are met. Applicants who pass the first hurdle, and thus meet the minimum qualification requirements, move on to the next, more-rigorous assessment tool. This strategy permits for better assessment tools to be used without depleting resources in the process and allows for the best qualified candidates to be considered for the position. Below are common examples of first, second and final hurdles OpDivs/StaffDivs may employ, if using up to three assessments to assess applicants, to determine which applicants will be placed on the Certificate of Eligibles.

Common first hurdles may include: Application and resume; occupational questionnaire; biodata; personality tests; verification.
Common second hurdles may include: Cognitive ability tests; job knowledge tests; situational judgement tests.
Common final hurdles may include: Assessment centers; written assessments; work samples; structured interviews.
Examples of approaches for multi-hurdle assessments are reflected below. NOTE: These examples of assessment tools, scores, or processes used are not meant to be prescriptive and could potentially vary in practice (e.g., using a different combination of assessment tools, using different cut-off scores for categories, etc.).
