{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb957fc",
   "metadata": {},
   "source": [
    "# Appendix ____________________ - Python Code To Create Chatbots about HR Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12390b",
   "metadata": {},
   "source": [
    "## 1) Chatbot 1 - Sentence-Based Transformer Chatbot That Leverages Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic==1.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061f2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\steve\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#import spacy\n",
    "#from spacy import displacy\n",
    "\n",
    "#from spacy.matcher import Matcher \n",
    "#from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from typing import List, Callable, Dict, Tuple, Set\n",
    "\n",
    "pd.set_option('max_colwidth', 600)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20647b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Sentence Transformer model optimized for  sentence cosine similarity calculations\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1ab571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a0da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/HR_Policy_Chatbot_Capstone_Project/corpus.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "\n",
    "#create list of sentences and words\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27ac829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create greetings and greetings function\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hello\"]\n",
    "\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0eb55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating response function \n",
    "def response(user_response):\n",
    "    chatbot_response=''\n",
    "    sentence_encodings=model.encode(sent_tokens, convert_to_tensor=True)# generate sentence transformer embeddings\n",
    "    sentence_encodings=sentence_encodings.cpu()\n",
    "    vals = cosine_similarity(sentence_encodings[-1].reshape(1, -1), sentence_encodings) #the chatbot conversation code \n",
    "    #in the next cell adds the question as the last sentence of the sentence tokens, before calling this response function.\n",
    "    #The code takes the last sentence (which is the question) and gets cosine similarities vs all the sentences in the corpus,\n",
    "    #including itself\n",
    "    idx=vals.argsort()[0][-2] #gets the index of the second highest similarity (the first highest would be the question itself)\n",
    "    flat = vals.flatten()#reduces dimension of cosine similarity array to be able to sort\n",
    "    flat.sort() #sort the cosine similarity values\n",
    "    second_cos_sim_val = flat[-2] #get the second highest cosine similarity value.\n",
    "    if(second_cos_sim_val==0): #check the second highest cosine similarity value. If it's zero return the no match response,\n",
    "        #else return highest cosine similarity sentence.\n",
    "        chatbot_response=chatbot_response+\"Sorry, I do not have an answer to your question in my database\"\n",
    "        return chatbot_response\n",
    "    else:\n",
    "        chatbot_response = chatbot_response+sent_tokens[idx] #use index of highest cosine similarity to get original sentence\n",
    "        return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de18951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Informational Chatbot About Human Resources policy at the Department of Health and Human Services.  Please note that this chatbot is just one graduate student's experimental final project and in no way actually speaks for the U.S. Department of Health and Human Resources. To end this session, please type exit.\n",
      "\n",
      "\n",
      "How is compensation determined when appointing special consultants?\n",
      "Answer: â§ 22.3(a) appointments of special consultants, provides:\n",
      "\n",
      "when the public health service requires the services of consultants who cannot be obtained when needed through regular civil service appointment or under the compensation provisions of the classification act of 1949, special consultants to assist and advise in the operations of the service may be appointed, subject to the provisions of the following paragraphs and in accordance with such instructions as may be issued from time to time by the secretary of health and human services.\n",
      "\n",
      "\n",
      "thank you\n",
      "Answer: You are welcome!\n"
     ]
    }
   ],
   "source": [
    "#Chatbot interaction code\n",
    "\n",
    "flag=True\n",
    "print(\"Welcome to the Informational Chatbot About Human Resources policy at the Department of Health and Human Services.  Please note that this chatbot is just one graduate student's experimental final project and in no way actually speaks for the U.S. Department of Health and Human Resources. To end this session, please type exit.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response!='exit':\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"Answer: You are welcome!\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Answer: \"+greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                print(\"Answer: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                print(\"\\n\")\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Thank you for using this chatbot service. Goodbye.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293aeedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ######################## UPDATE THIS WHEN ASSESSING MODEL PERFORMANCE #####################################################\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "chatbot_models = []\n",
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(1)\n",
    "    \n",
    "model_1_performance_list = [\"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64761b2f",
   "metadata": {},
   "source": [
    "## 2) Chatbot 2 - Fine-Tune GPT2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bbb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59372a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## UPDATE THIS TO USE FINE TUNING QUESTIONS SPECIFIC TO THE CORPUS ###############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
    "\n",
    "# Load the GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# Define multiple question and answer pairs\n",
    "qa_pairs = [\n",
    "    (\"Which species are at the top of the food chain in coral reefs?\", \"sharks and giant moray. STOP\"),\n",
    "    (\"What fish eat coral?\", \"parrotfish and butterflyfish. STOP\"),\n",
    "    (\"Which coral reef fish has the shortest lifespan?\", \"seven-figure pygmy goby. STOP\"),\n",
    "    (\"What species in coral reefs can inflate themselves?\", \"puffers, striated frogfish, and porcupinefish. STOP\"),\n",
    "    (\"How do sea anemones protect themselves?\", \"tentacles that bristle tiny harpoons primed with toxins. STOP\"),\n",
    "    (\"What species commonly serves as a cleaner fish?\", \"bluestreak cleaner wrasse. STOP\"),\n",
    "    (\"What species in coral reefs eat sponges?\", \"emperor angelfish. STOP\"),\n",
    "    (\"What species in coral reefs eat stingrays?\", \"caribbean reef shark and great hammerheads. STOP\"),\n",
    "    (\"Which species in coral reefs are hermaphrodites\", \"grouper. STOP\"),\n",
    "    (\"What species in coral reefs is known to eat birds?\", \"blacktip reef shark. STOP\"),\n",
    "    (\"What percent of the ocean is covered by coral reefs?\", \"less than 1%. STOP\"),\n",
    "    (\"When is the colouration of clown triggerfish vivid?\", \"when they are not threatened. STOP\"),\n",
    "    (\"What are reef lizardfish coated in?\", \"mucus. STOP\"),\n",
    "    (\"Name some coral reef fish that feed on zooplankton?\", \"damselfish, surgeonfish, and cardinalfish. STOP\"),\n",
    "    (\"Parrotfish often school with what other species?\", \"spinefoot rabbitfish. STOP\"),\n",
    "    (\"What species eat sea anemones?\", \"saddle butterflyfish. STOP\"),\n",
    "    (\"How many venomous spines does the reef stonefish have?\", \"13. STOP\"),\n",
    "    (\"What predators eat reef stonefish?\", \"bottom feeding rays, sharks, and Stokes' seasnake. STOP\"),\n",
    "    (\"What toxin is sometimes found coral reef carnivores?\", \"ciguatera toxin. STOP\"),\n",
    "    (\"How long are whitetip reef sharks?\", \"usually less than 1.6 meters. STOP\"),\n",
    "    (\"How long are whitetip reef sharks?\", \"less than 1.6 meters. STOP\"),\n",
    "    (\"What predators eat whitetip reef sharks?\", \"tiger sharks and Galapagos sharks. STOP\"),\n",
    "    (\"What predators eat blacktip reef sharks?\", \"groupers, grey reef sharks, tiger sharks, and members of their own species. STOP\"),\n",
    "    (\"What sharks are known for having small home ranges?\", \"blacktip reef sharks. STOP\"),\n",
    "    (\"Are grey reef sharks social or territorial?\", \"social. STOP\"),\n",
    "    (\"Name a coral reef shark that likes drop-offs?\", \"whitetip reef shark, blacktip reef shark, or grey reef shark. STOP\"),\n",
    "    (\"What do benthic algae grow on?\", \"dead coral and other inert surfaces. STOP\"),\n",
    "    (\"What do goatfish use to search for food?\", \"chemosensory barbels (whiskers). STOP\"),   \n",
    "    (\"Goatfish commonly change their colouration to match that of which fish?\", \"snapper. STOP\"),   \n",
    "    (\"What does the tassled scorpionfish camouflage itself to look like?\", \"coral encrusted sea floor. STOP\"),  \n",
    "    (\"What are some threats to the survival of coral reef fish?\", \"pollution, overfishing, and habitat loss and degradation. STOP\"),  \n",
    "    (\"What percent of marine fish species live in coral reefs?\", \"25 percent. STOP\"), \n",
    "    (\"Where do most coral reef fish have spines?\", \"on their fins. STOP\"),  \n",
    "    (\"Why do toadfish sing?\", \"to attract mates. STOP\"), \n",
    "    (\"What do Synchiropus splendidus eat?\", \"small crustaceans and other invertebrates. STOP\"), \n",
    "    (\"What color is the mouth of the clown triggerfish?\", \"bright yellow. STOP\"),   \n",
    "    (\"How many species of parasites would go extinct if one coral reef fish species of average size went extinct?\", \"at least 10. STOP\"),      \n",
    "    (\"What types of sharks can enter brackish or freshwater environments?\", \"blacktip reef sharks. STOP\"),\n",
    "    (\"What sound frequency do whitetip reef sharks recognize as coming from struggling fish?\", \"25 - 100 Hz. STOP\"),\n",
    "    (\"Can whitetip reef sharks rest on the sea floor or do they have to keep moving?\", \"They can rest on the sea floor. STOP\"),    \n",
    "    (\"Are whitetip reef sharks better at hunting in tight crevices or in open water?\", \"tight crevices. STOP\"),\n",
    "    (\"How long are Caribbean reef sharks?\", \"up to 3 meters. STOP\"), \n",
    "    (\"Titan triggerfish use jets of water to expose what species buried in the sand?\", \"sand dollars. STOP\"), \n",
    "    (\"Are coral reef fish bodies often optimized for straight-line speed or for manoeuvrability?\", \"manoeuvrability. STOP\"),\n",
    "    (\"Where does the foureye butterflyfish get its name from?\", \"the large dark spots each side of their bodies. STOP\"), \n",
    "    (\"How long are striated frogfish?\", \"about 10 centimeters. STOP\"),\n",
    "    (\"Why do some coral reef fish engage in schooling?\", \"defense against predators through better predator detection. STOP\"),\n",
    "    (\"What are lateral lines in coral reef fish?\", \"pressure sensors that allow schooling fish to feel each others' movements and stay synchronized. STOP\"),\n",
    "    (\"What is a primary producer?\", \"a plant that synthesizes food from solar energy. STOP\"), \n",
    "    (\"What is the name for the stinging cells in fire coral?\", \" nematocysts. STOP\")\n",
    "]\n",
    "\n",
    "# Concatenate the question and answer pairs with appropriate formatting\n",
    "formatted_pairs = [f\"Q: {q}\\nA: {a}\\n\" for q, a in qa_pairs]\n",
    "qa_text = \"\\n\".join(formatted_pairs)\n",
    "\n",
    "# Fine-tune the GPT-2 model with the Q&A pairs\n",
    "inputs = tokenizer.encode(qa_text, return_tensors=\"pt\", max_length = 1000)\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Run the fine-tuning loop (example: 1 epoch)\n",
    "for j in range(120):\n",
    "    print (j)\n",
    "    outputs = model(inputs, labels=inputs)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine-tuned-gpt2\")\n",
    "\n",
    "# Load the fine-tuned model\n",
    "fine_tuned_model = GPT2LMHeadModel.from_pretrained(\"fine-tuned-gpt2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### UPDATE THIS SECTTION WEHN ASSESSING MODEL PERFORMANCE ########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: How many species of fish live in coral reefs?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28502853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What is the most venomous fish?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c021ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What sharks live in coral reefs?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What fish are poisonous?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34030f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What fish can electrocute you?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90edc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species can sting you?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cedfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are parasitic?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are venomous?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are known for attacking scuba divers?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What are common herbivorous fish?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Why do fish camouflage themselves?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c68605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: How do fish get rid of their parasites?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de190098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species have a mutualistic relationship?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8587c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species have a commensalistic relationship?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Where in the world are coral reefs found?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species engage in schooling?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a09451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are ambush predators?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4926ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Which species are ambush predators?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d405fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Why are some coral reef fish colorful?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Which species is blue?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What is the slowest species that lives in coral reefs?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "########################################## UPDATE THIS AFTER ASSESSING MODEL PERFORMANCE ###################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(2)\n",
    "    \n",
    "    \n",
    "model_2_performance_list = [\"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\", \n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3fafe",
   "metadata": {},
   "source": [
    "## 3) Chatbot 3 - Chatbot Emphasizing Cosine Similarity of TF-IDF Representations of Sententces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72628a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff400af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) # for downloading packages\n",
    "#nltk.download('punkt') # first-time use only\n",
    "#nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b54d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/HR_Policy_Chatbot_Capstone_Project/corpus.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd876b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3be15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd25bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hi\", \"Hey\", \"*nods*\", \"Hi there\", \"Hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "075fbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f86069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am the Unofficial Department of Health and Human Services (HHS) Human Resources (HR) Policy Chatbot! I will answer your queries related to HR policy at HHS. Please note that this resource is one curious graduate student's experimental capstone project and does not actually speak for the U.S. Department of Health and Human Services. If you want to exit, type bye.\n",
      "what are the educational requirements for appointed special consultants?\n",
      "â§ 209(f) special consultants\n",
      "42 c.f.r.\n",
      "how is compensation determined for appointed special consultants?\n",
      "â§ 209(f) special consultants\n",
      "42 c.f.r.\n",
      "thank you\n",
      "You are welcome.\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"Hello, I am the Unofficial Department of Health and Human Services (HHS) Human Resources (HR) Policy Chatbot! I will answer your queries related to HR policy at HHS. Please note that this resource is one curious graduate student's experimental capstone project and does not actually speak for the U.S. Department of Health and Human Services. If you want to exit, type bye.\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"You are welcome.\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(greeting(user_response))\n",
    "            else:\n",
    "                print(\"\",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## UPDATE THIS SECTION AFTER ASSESSING MODEL PERFORMANCE ##############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(3)\n",
    "\n",
    "model_3_performance_list = [\"Incorrect\",\n",
    "                          \"Incorrect\", \n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800bd6e",
   "metadata": {},
   "source": [
    "## 4) Chatbot 4 - Distillbert Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc568ad3",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a29dcead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/HR_Policy_Chatbot_Capstone_Project/corpus.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eda8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'official transcript', score: 0.4861, start: 19914, end: 19933\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "#context = r\"\"\"\n",
    "#Extractive Question Answering is the task of extracting an answer from a text given a question. An example     of a\n",
    "#question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "#a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\n",
    "#\"\"\"\n",
    "\n",
    "result = question_answerer(question=\"What is a good example of a question answering dataset?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "\n",
    "#Answer: 'SQuAD dataset', score: 0.5152, start: 147, end: 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3327c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'professional experience and stature', score: 0.3316, start: 5987, end: 6022\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######################### UPDATE THIS SECTION TO ASK QUESTIONS ABOUT HHS HR POLICY #########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = question_answerer(question=\"What are the experience requirements for appointed special consultants?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What is the most venomous fish?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2880b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What sharks live in coral reefs?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afaa7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What fish are poisonous?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98875a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What fish can electrocute you?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species can sting you?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species are parasitic?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2871306",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species are venomous?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c960a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species are known for attacking scuba divers?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What are common herbivorous fish?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"Why do fish camouflage themselves?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f168ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"How do fish get rid of their parasites?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species have mutualistic relationships?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c70334",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species have commensalistic relationships?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"Where in the world are coral reefs found?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What species engage in schooling?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"Which species are ambush predators?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"Why are some coral reef fish colorful?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"Which species is blue?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fbead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=\"What is the slowest species that lives in coral reefs?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d86cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######################################## UPDATE THIS TO REFLECT MODEL PERFORMANCE #############################################\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(4)\n",
    "\n",
    "model_4_performance_list = [\"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7154785",
   "metadata": {},
   "source": [
    "## 5) Chatbot 5 - Roberta Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a16d72",
   "metadata": {},
   "source": [
    "https://huggingface.co/deepset/roberta-base-squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2edda303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline, RobertaTokenizer, RobertaModel, TFRobertaModel\n",
    "from transformers import optimization\n",
    "\n",
    "batch_size = 96\n",
    "n_epochs = 2\n",
    "base_LM_model = \"roberta-base\"\n",
    "max_seq_len = 386\n",
    "learning_rate = 3e-5\n",
    "#lr_schedule = optimization.LinearWarmup\n",
    "warmup_proportion = 0.2\n",
    "doc_stride=128\n",
    "max_query_length=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50844ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install farm-haystack[inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e97ea5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d458dbd058842dfb8c27e729da3d0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622538565aea413f93839bf898b9dfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ac3575a9074d8bbc88e6015da435d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65bd10e419b47ab9c6bfc48c85905c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83f306902694c6b822c1d063d5bd9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6730989e110f43b0a3a8bf588202de63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.18069009482860565,\n",
       " 'start': 5987,\n",
       " 'end': 6049,\n",
       " 'answer': 'professional experience and stature in their area of expertise'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################# UPDATE THIS SECTION TO REFLECT HHS HR POLICY QUESTIONS ######################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from haystack.reader.farm import FARMReader\n",
    "\n",
    "#reader = TransformersReader(model_name_or_path=\"deepset/roberta-base-squad2\",tokenizer=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'What are the experience requirements for appointed special consultants?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25da7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0006357975071296096,\n",
       " 'start': 5987,\n",
       " 'end': 6010,\n",
       " 'answer': 'professional experience'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'How is compensation determined when appointing special consultants?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d764b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.01072785072028637,\n",
       " 'start': 5987,\n",
       " 'end': 6022,\n",
       " 'answer': 'professional experience and stature'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What are the educational requirements for appointed special consultants?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a27464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What fish are poisonous?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e35cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What fish can electrocute you?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43836d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species can sting you?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23259d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are parasitic?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb657d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are venomous?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are known for attacking scuba divers?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bba596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What are common herbivorous fish?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf693fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Why do fish camouflage themselves?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'How do fish get rid of their parasites?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species have mutualistic relationships?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species have commensalistic relationships?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Where in the world are coral reefs found?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0579fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species engage in schooling?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are ambush predators?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb489c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Why are some coral reef fish colorful?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c717362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Which species is blue?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What is the slowest species that lives in coral reefs?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35537bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################### UPDATE THIS TO REFLECT PERFORMANCE ASSESSMENT OF MODEL ###############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(5)\n",
    "\n",
    "model_5_performance_list = [\"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81376376",
   "metadata": {},
   "source": [
    "## 6) Evaluation of Chatbot Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "chatbot_performance_df = pd.DataFrame({'Correct': [100 * model_1_performance_list.count(\"Correct\")/len(model_1_performance_list),\n",
    "                               100 * model_2_performance_list.count(\"Correct\")/len(model_2_performance_list),\n",
    "                               100 * model_3_performance_list.count(\"Correct\")/len(model_3_performance_list),\n",
    "                               100 * model_4_performance_list.count(\"Correct\")/len(model_4_performance_list),\n",
    "                               100 * model_5_performance_list.count(\"Correct\")/len(model_5_performance_list)],\n",
    "                    'Partially Correct': [100 * model_1_performance_list.count(\"Partially Correct\")/len(model_1_performance_list),\n",
    "                               100 * model_2_performance_list.count(\"Partially Correct\")/len(model_2_performance_list),\n",
    "                               100 * model_3_performance_list.count(\"Partially Correct\")/len(model_3_performance_list),\n",
    "                               100 * model_4_performance_list.count(\"Partially Correct\")/len(model_4_performance_list),\n",
    "                               100 * model_5_performance_list.count(\"Partially Correct\")/len(model_5_performance_list)],\n",
    "                   'Incorrect': [100 * model_1_performance_list.count(\"Incorrect\")/len(model_1_performance_list),\n",
    "                               100 * model_2_performance_list.count(\"Incorrect\")/len(model_2_performance_list),\n",
    "                               100 * model_3_performance_list.count(\"Incorrect\")/len(model_3_performance_list),\n",
    "                               100 * model_4_performance_list.count(\"Incorrect\")/len(model_4_performance_list),\n",
    "                               100 * model_5_performance_list.count(\"Incorrect\")/len(model_5_performance_list)]},\n",
    "                  index=['1', '2', '3', '4', '5'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "ax = chatbot_performance_df.plot(kind = 'bar', stacked = True, figsize = (12, 12), fontsize = 13, color = [\"forestgreen\", \"goldenrod\", 'firebrick'])\n",
    "\n",
    "ax.set_xticklabels(labels = [\"Sentence-Based Transformer\", \n",
    "                             \"Fine-Tuned GPT2\",\n",
    "                             \"TF-IDF Cosine Similarity\",\n",
    "                             \"DistilBERT\",\n",
    "                             \"Roberta\"], rotation = 45)\n",
    "ax.set_xlabel(\"Chatbot Model\", fontsize=18)\n",
    "ax.set_ylabel(\"Percent of Responses That Are Correct, Partially Correct, and Incorrect\", fontsize=17)\n",
    "ax.set_title('Stacked Barplot Summarizing Performance Of Chatbots About HHS HR Policy', fontsize = 20)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.55), loc='upper left', borderaxespad=0, fontsize = 13)\n",
    "\n",
    "plt.show();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
